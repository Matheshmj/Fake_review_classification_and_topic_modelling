{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8N8EtZtyZH/DDQuaItwpS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Matheshmj/Fake_review_classification_and_topic_modelling/blob/main/DL_MODELS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Preprocessing**"
      ],
      "metadata": {
        "id": "YXAkmw-MOCEF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LtzJ3WcEEz7"
      },
      "outputs": [],
      "source": [
        "###Preprocessing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load data\n",
        "data = pd.read_csv('/content/Downloads_cleaned_review_data.csv')\n",
        "data['label_encoded'] = LabelEncoder().fit_transform(data['label'])\n",
        "\n",
        "# Split data\n",
        "X = data['joined_text'].astype(str)  # Convert to string\n",
        "y = data['label_encoded']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization and Padding\n",
        "vocab_size = 10000\n",
        "max_length = 100\n",
        "embedding_dim = 100\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_length, padding='post', truncating='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_length, padding='post', truncating='post')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RNN Model**"
      ],
      "metadata": {
        "id": "U4sWrSNAN6u6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN, SpatialDropout1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Build RNN Model\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    SpatialDropout1D(0.2),\n",
        "    SimpleRNN(64, return_sequences=False),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n",
        "\n",
        "# Compile the Model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the Model\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train_pad, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=64,\n",
        "                    validation_split=0.2,\n",
        "                    callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the Model\n",
        "y_pred = (model.predict(X_test_pad) > 0.5).astype(\"int32\")\n",
        "print(\"Classification Report for RNN:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['CG', 'OR']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4umBSYnFRp_",
        "outputId": "bc6bbba0-77b7-47bb-ebea-ac891b154412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 46ms/step - accuracy: 0.5244 - loss: 0.6895 - val_accuracy: 0.6044 - val_loss: 0.6604\n",
            "Epoch 2/10\n",
            "\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 51ms/step - accuracy: 0.6134 - loss: 0.6486 - val_accuracy: 0.6363 - val_loss: 0.6331\n",
            "Epoch 3/10\n",
            "\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 48ms/step - accuracy: 0.7338 - loss: 0.5464 - val_accuracy: 0.7046 - val_loss: 0.5816\n",
            "Epoch 4/10\n",
            "\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 50ms/step - accuracy: 0.7777 - loss: 0.4903 - val_accuracy: 0.7151 - val_loss: 0.5700\n",
            "Epoch 5/10\n",
            "\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 47ms/step - accuracy: 0.7720 - loss: 0.4929 - val_accuracy: 0.7879 - val_loss: 0.4744\n",
            "Epoch 6/10\n",
            "\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 51ms/step - accuracy: 0.8450 - loss: 0.3915 - val_accuracy: 0.7861 - val_loss: 0.5030\n",
            "Epoch 7/10\n",
            "\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 51ms/step - accuracy: 0.8727 - loss: 0.3283 - val_accuracy: 0.5642 - val_loss: 0.6671\n",
            "Epoch 8/10\n",
            "\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 46ms/step - accuracy: 0.5950 - loss: 0.6376 - val_accuracy: 0.7451 - val_loss: 0.5361\n",
            "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
            "Classification Report for RNN:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CG       0.80      0.78      0.79      4016\n",
            "          OR       0.79      0.81      0.80      4071\n",
            "\n",
            "    accuracy                           0.79      8087\n",
            "   macro avg       0.79      0.79      0.79      8087\n",
            "weighted avg       0.79      0.79      0.79      8087\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LSTM Model**"
      ],
      "metadata": {
        "id": "vPv1axz_OI_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM, SpatialDropout1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Build LSTM Model\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    SpatialDropout1D(0.2),\n",
        "    LSTM(64, return_sequences=False),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n",
        "\n",
        "# Compile the Model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the Model\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train_pad, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=64,\n",
        "                    validation_split=0.2,\n",
        "                    callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the Model\n",
        "y_pred = (model.predict(X_test_pad) > 0.5).astype(\"int32\")\n",
        "print(\"Classification Report for LSTM:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['CG', 'OR']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFjCP7DzHiRx",
        "outputId": "c9cd7cc5-0699-4e3f-b656-1021a3f1c2ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 127ms/step - accuracy: 0.5344 - loss: 0.6762 - val_accuracy: 0.7296 - val_loss: 0.5682\n",
            "Epoch 2/10\n",
            "\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 124ms/step - accuracy: 0.7963 - loss: 0.4640 - val_accuracy: 0.8688 - val_loss: 0.3127\n",
            "Epoch 3/10\n",
            "\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 127ms/step - accuracy: 0.8963 - loss: 0.2514 - val_accuracy: 0.8943 - val_loss: 0.2578\n",
            "Epoch 4/10\n",
            "\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 128ms/step - accuracy: 0.9341 - loss: 0.1696 - val_accuracy: 0.8958 - val_loss: 0.2485\n",
            "Epoch 5/10\n",
            "\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 128ms/step - accuracy: 0.9544 - loss: 0.1205 - val_accuracy: 0.8941 - val_loss: 0.2562\n",
            "Epoch 6/10\n",
            "\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 128ms/step - accuracy: 0.9613 - loss: 0.1015 - val_accuracy: 0.8943 - val_loss: 0.2991\n",
            "Epoch 7/10\n",
            "\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 128ms/step - accuracy: 0.9719 - loss: 0.0752 - val_accuracy: 0.8899 - val_loss: 0.3416\n",
            "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step\n",
            "Classification Report for LSTM:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CG       0.89      0.90      0.89      4016\n",
            "          OR       0.90      0.89      0.89      4071\n",
            "\n",
            "    accuracy                           0.89      8087\n",
            "   macro avg       0.89      0.89      0.89      8087\n",
            "weighted avg       0.89      0.89      0.89      8087\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **BiLSTM Model**"
      ],
      "metadata": {
        "id": "i_KnPiF_OP4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BiLSTM Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM, Bidirectional, SpatialDropout1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Build BiLSTM Model\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    SpatialDropout1D(0.2),\n",
        "    Bidirectional(LSTM(64, return_sequences=False)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n",
        "\n",
        "# Compile the Model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the Model\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train_pad, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=64,\n",
        "                    validation_split=0.2,\n",
        "                    callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the Model\n",
        "y_pred = (model.predict(X_test_pad) > 0.5).astype(\"int32\")\n",
        "print(\"Classification Report for BiLSTM:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['CG', 'OR']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTdRtV5qJiDq",
        "outputId": "fd2443f8-f6b4-4fe0-9c57-e03214908e3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 223ms/step - accuracy: 0.7706 - loss: 0.4316 - val_accuracy: 0.9079 - val_loss: 0.2197\n",
            "Epoch 2/10\n",
            "\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 227ms/step - accuracy: 0.9327 - loss: 0.1650 - val_accuracy: 0.9122 - val_loss: 0.2091\n",
            "Epoch 3/10\n",
            "\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 226ms/step - accuracy: 0.9579 - loss: 0.1075 - val_accuracy: 0.9068 - val_loss: 0.2212\n",
            "Epoch 4/10\n",
            "\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 225ms/step - accuracy: 0.9706 - loss: 0.0754 - val_accuracy: 0.9068 - val_loss: 0.2759\n",
            "Epoch 5/10\n",
            "\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 223ms/step - accuracy: 0.9786 - loss: 0.0590 - val_accuracy: 0.9054 - val_loss: 0.2750\n",
            "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step\n",
            "Classification Report for BiLSTM:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CG       0.90      0.92      0.91      4016\n",
            "          OR       0.92      0.90      0.91      4071\n",
            "\n",
            "    accuracy                           0.91      8087\n",
            "   macro avg       0.91      0.91      0.91      8087\n",
            "weighted avg       0.91      0.91      0.91      8087\n",
            "\n"
          ]
        }
      ]
    }
  ]
}